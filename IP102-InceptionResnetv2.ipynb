{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":3132677,"sourceType":"datasetVersion","datasetId":1908726}],"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.optim.lr_scheduler import StepLR\nfrom torch.utils.data import DataLoader\nfrom torchvision import datasets, transforms\nfrom sklearn.metrics import classification_report, confusion_matrix\nimport numpy as np\nimport os\nfrom tqdm import tqdm\nimport timm  # ‚úÖ Use timm for InceptionResNetV2\n\n# ------------------ Configs ------------------ #\ndata_dir = '/kaggle/input/ip02-dataset/classification/'\nbatch_size = 64\nlearning_rate = 0.01\nnum_epochs = 30\nlr_step_size = 40\nlr_gamma = 0.1\nmomentum = 0.9\nweight_decay = 0.0005\ndropout_rate = 0.3\ninput_size = 299  # ‚úÖ InceptionResNetV2 prefers 299x299 input\nnum_workers = 4\n\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n\n# ------------------ Data Transforms ------------------ #\ndata_transforms = {\n    'train': transforms.Compose([\n        transforms.Resize((input_size, input_size)),\n        transforms.RandomHorizontalFlip(),\n        transforms.ToTensor(),\n        transforms.Normalize([0.5, 0.5, 0.5],\n                             [0.5, 0.5, 0.5])  # Optional: use standard normalization if pretrained model differs\n    ]),\n    'val': transforms.Compose([\n        transforms.Resize((input_size, input_size)),\n        transforms.ToTensor(),\n        transforms.Normalize([0.5, 0.5, 0.5],\n                             [0.5, 0.5, 0.5])\n    ]),\n    'test': transforms.Compose([\n        transforms.Resize((input_size, input_size)),\n        transforms.ToTensor(),\n        transforms.Normalize([0.5, 0.5, 0.5],\n                             [0.5, 0.5, 0.5])\n    ])\n}\n\n# ------------------ Datasets & Dataloaders ------------------ #\nimage_datasets = {\n    x: datasets.ImageFolder(os.path.join(data_dir, x), transform=data_transforms[x])\n    for x in ['train', 'val', 'test']\n}\n\nnum_classes = len(image_datasets['train'].classes)\nprint(\"‚úÖ num_classes set to:\", num_classes)\n\ndataloaders = {\n    x: DataLoader(image_datasets[x], batch_size=batch_size, shuffle=(x != 'test'), num_workers=num_workers)\n    for x in ['train', 'val', 'test']\n}\n\nclass_names = image_datasets['train'].classes\n\n# ------------------ Model Setup (InceptionResNetV2) ------------------ #\nmodel = timm.create_model('inception_resnet_v2', pretrained=True)\nmodel.classifier = nn.Sequential(\n    nn.Dropout(p=dropout_rate),\n    nn.Linear(model.classifier.in_features, num_classes)\n)\nmodel = model.to(device)\n\ncriterion = nn.CrossEntropyLoss()\noptimizer = optim.SGD(model.parameters(), lr=learning_rate,\n                      momentum=momentum, weight_decay=weight_decay)\nscheduler = StepLR(optimizer, step_size=lr_step_size, gamma=lr_gamma)\n\n# ------------------ Training Loop ------------------ #\ndef train_model():\n    best_val_acc = 0.0\n    best_model_path = 'best_inceptionresnet_model.pth'\n\n    for epoch in range(num_epochs):\n        print(f\"Epoch {epoch+1}/{num_epochs}\")\n        print('-' * 20)\n\n        for phase in ['train', 'val']:\n            model.train() if phase == 'train' else model.eval()\n\n            running_loss = 0.0\n            running_corrects = 0\n\n            for inputs, labels in dataloaders[phase]:\n                inputs = inputs.to(device)\n                labels = labels.to(device)\n\n                optimizer.zero_grad()\n                with torch.set_grad_enabled(phase == 'train'):\n                    outputs = model(inputs)\n                    _, preds = torch.max(outputs, 1)\n                    loss = criterion(outputs, labels)\n\n                    if phase == 'train':\n                        loss.backward()\n                        optimizer.step()\n\n                running_loss += loss.item() * inputs.size(0)\n                running_corrects += torch.sum(preds == labels.data)\n\n            epoch_loss = running_loss / len(image_datasets[phase])\n            epoch_acc = running_corrects.double() / len(image_datasets[phase])\n\n            print(f\"{phase} Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f}\")\n\n            if phase == 'val' and epoch_acc > best_val_acc:\n                best_val_acc = epoch_acc\n                torch.save(model.state_dict(), best_model_path)\n                print(f\"‚úÖ Best model saved at epoch {epoch+1} with val acc: {epoch_acc:.4f}\")\n\n        scheduler.step()\n\n    print(f\"\\nüèÅ Training completed. Best Val Acc: {best_val_acc:.4f}\")\n\n# ------------------ Evaluation on Test Set ------------------ #\ndef evaluate_model():\n    model.eval()\n    all_preds = []\n    all_labels = []\n    top1_correct = 0\n    top5_correct = 0\n    total = 0\n\n    with torch.no_grad():\n        for inputs, labels in tqdm(dataloaders['test'], desc=\"Evaluating\"):\n            inputs = inputs.to(device)\n            labels = labels.to(device)\n\n            outputs = model(inputs)\n            _, top1_preds = outputs.topk(1, dim=1)\n            top5_preds = outputs.topk(5, dim=1).indices\n\n            all_preds.extend(top1_preds.squeeze().cpu().numpy())\n            all_labels.extend(labels.cpu().numpy())\n\n            top1_correct += (top1_preds.squeeze() == labels).sum().item()\n\n            for i in range(labels.size(0)):\n                if labels[i] in top5_preds[i]:\n                    top5_correct += 1\n\n            total += labels.size(0)\n\n    top1_acc = top1_correct / total\n    top5_acc = top5_correct / total\n\n    print(f\"\\n‚úÖ Top-1 Accuracy: {top1_acc:.4f}\")\n    print(f\"‚úÖ Top-5 Accuracy: {top5_acc:.4f}\\n\")\n\n    print(\"üìä Classification Report:\")\n    print(classification_report(all_labels, all_preds, target_names=class_names))\n\n    print(\"üßæ Confusion Matrix:\")\n    print(confusion_matrix(all_labels, all_preds))\n\n\n# ------------------ Run ------------------ #\nif __name__ == \"__main__\":\n    train_model()\n    evaluate_model()\n","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}